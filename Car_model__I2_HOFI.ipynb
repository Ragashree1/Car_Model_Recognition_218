{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RhbizF66JDj"
      },
      "source": [
        "# Importing Dataset from gdrive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duX0hZoM5lCE",
        "outputId": "654c6d8e-d6f8-4703-8f53-99aad08f11cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ZIPPED_PATH=\"/content/drive/MyDrive/car/car.zip\""
      ],
      "metadata": {
        "id": "wZLvriwR7oQF"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as T\n",
        "import zipfile\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "import os\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Extract dataset\n",
        "extract_folder = \"/content/cars\"\n",
        "if not os.path.exists(extract_folder):\n",
        "    os.makedirs(extract_folder)\n",
        "\n",
        "with zipfile.ZipFile(ZIPPED_PATH, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_folder)\n",
        "print(\"Extraction complete.\")\n",
        "\n",
        "# Load pre-trained ResNet-50 model\n",
        "resnet = models.resnet50(pretrained=True)\n",
        "resnet.fc = torch.nn.Identity()  # Remove final layer to get feature vector\n",
        "resnet.to(device)\n",
        "resnet.eval()\n",
        "\n",
        "\n",
        "# Define Image Transform\n",
        "transform = T.Compose([\n",
        "    T.Resize((224, 224)),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Function to extract features using ResNet-50\n",
        "def extract_features(img_path):\n",
        "    try:\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "    except Exception as e:\n",
        "        print(\"Error opening image:\", e)\n",
        "        return None\n",
        "    image = transform(image).unsqueeze(0).to(device)\n",
        "    with torch.no_grad():\n",
        "        feature_vector = resnet(image).cpu().numpy().flatten()\n",
        "    return feature_vector\n",
        "\n",
        "# Define I2-HOFI Classifier\n",
        "class I2HOFI(nn.Module):\n",
        "    def __init__(self, input_dim, num_classes):\n",
        "        super(I2HOFI, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, 512)\n",
        "        self.bn1 = nn.BatchNorm1d(512)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.bn2 = nn.BatchNorm1d(256)\n",
        "        self.fc3 = nn.Linear(256, num_classes)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.bn1(self.fc1(x)))\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(self.bn2(self.fc2(x)))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Load dataset\n",
        "trainDF = pd.read_excel('/content/drive/MyDrive/car/cars_with_class_names.xlsx', sheet_name='train')\n",
        "testDF = pd.read_excel('/content/drive/MyDrive/car/cars_with_class_names.xlsx', sheet_name='test')\n",
        "\n",
        "# Convert DataFrame to NumPy Array\n",
        "trainArray = trainDF.to_numpy()\n",
        "testArray = testDF.to_numpy()\n",
        "\n",
        "\n",
        "# Paths to images\n",
        "train_folder = os.path.join(extract_folder, \"cars_train\", \"cars_train\")\n",
        "test_folder = os.path.join(extract_folder, \"cars_test\", \"cars_test\")\n",
        "\n",
        "# Extract train features and labels\n",
        "X_train, y_train = [], []\n",
        "for entry in trainArray:\n",
        "    img_path = os.path.join(train_folder, entry[7])\n",
        "    if os.path.exists(img_path):\n",
        "        feature_vector = extract_features(img_path)\n",
        "        if feature_vector is not None:\n",
        "            X_train.append(feature_vector)\n",
        "            y_train.append(entry[6])\n",
        "\n",
        "# Extract test features and labels\n",
        "X_test, y_test = [], []\n",
        "for entry in testArray:\n",
        "    filename = str(entry[6]).strip(\"'\\\"\")\n",
        "    img_path = os.path.join(test_folder, filename)\n",
        "    if os.path.exists(img_path):\n",
        "        feature_vector = extract_features(img_path)\n",
        "        if feature_vector is not None:\n",
        "            X_test.append(feature_vector)\n",
        "            y_test.append(entry[5])\n",
        "\n",
        "# Convert to NumPy arrays\n",
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)\n",
        "X_test = np.array(X_test)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "\n",
        "print(\"Class distribution in train set:\", Counter(y_train))\n",
        "\n",
        "\n",
        "print(f\"X_train shape: {X_train.shape}, X_test shape: {X_test.shape}\")\n",
        "\n",
        "# Encode labels into numeric values\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "y_test_encoded = label_encoder.transform(y_test)\n",
        "\n",
        "# Convert to tensors\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
        "y_train_tensor = torch.tensor(y_train_encoded, dtype=torch.long).to(device)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
        "y_test_tensor = torch.tensor(y_test_encoded, dtype=torch.long).to(device)\n",
        "\n",
        "# Initialize I2-HOFI model\n",
        "num_classes = len(np.unique(y_train_encoded))\n",
        "i2_hofi_model = I2HOFI(input_dim=X_train.shape[1], num_classes=num_classes).to(device)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(i2_hofi_model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 150\n",
        "for epoch in range(num_epochs):\n",
        "    i2_hofi_model.train()\n",
        "    optimizer.zero_grad()\n",
        "    outputs = i2_hofi_model(X_train_tensor)\n",
        "    loss = criterion(outputs, y_train_tensor)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Evaluate model\n",
        "i2_hofi_model.eval()\n",
        "with torch.no_grad():\n",
        "    y_pred_probs = i2_hofi_model(X_test_tensor)\n",
        "    y_pred = torch.argmax(y_pred_probs, dim=1).cpu().numpy()\n",
        "\n",
        "y_test_numpy = y_test_tensor.cpu().numpy()\n",
        "accuracy = accuracy_score(y_test_numpy, y_pred)\n",
        "precision = precision_score(y_test_numpy, y_pred, average='weighted')\n",
        "recall = recall_score(y_test_numpy, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test_numpy, y_pred, average='weighted')\n",
        "\n",
        "print(f\"I2-HOFI Model Accuracy: {accuracy:.4f}\")\n",
        "print(f\"I2-HOFI Model Precision: {precision:.4f}\")\n",
        "print(f\"I2-HOFI Model Recall Score: {recall:.4f}\")\n",
        "print(f\"I2-HOFI Model F1 Score: {f1:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8czBu0H7eWd",
        "outputId": "2c744a62-dfb5-4e50-b4ab-ef4c0eeee399"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extraction complete.\n",
            "Class distribution in train set: Counter({'GMC Savana Van 2012': 68, 'Chrysler 300 SRT-8 2010': 49, 'Mitsubishi Lancer Sedan 2012': 48, 'Mercedes-Benz 300-Class Convertible 1993': 48, 'Jaguar XK XKR 2012': 47, 'Chevrolet Corvette ZR1 2012': 47, 'Volvo 240 Sedan 1993': 46, 'Volkswagen Golf Hatchback 1991': 46, 'Bentley Continental GT Coupe 2007': 46, 'Audi S6 Sedan 2011': 46, 'Ford GT Coupe 2006': 46, 'Mercedes-Benz C-Class Sedan 2012': 46, 'Nissan 240SX Coupe 1998': 46, 'Suzuki Kizashi Sedan 2012': 46, 'Eagle Talon Hatchback 1998': 46, 'Dodge Durango SUV 2007': 46, 'Geo Metro Convertible 1993': 45, 'Chevrolet Malibu Sedan 2007': 45, 'Jeep Grand Cherokee SUV 2012': 45, 'Cadillac Escalade EXT Crew Cab 2007': 45, 'Bentley Continental Flying Spur Sedan 2007': 45, 'Chevrolet Avalanche Crew Cab 2012': 45, 'Ford F-150 Regular Cab 2007': 45, 'Aston Martin V8 Vantage Convertible 2012': 45, 'Chevrolet Camaro Convertible 2012': 45, 'Mercedes-Benz S-Class Sedan 2012': 45, 'GMC Acadia SUV 2012': 45, 'Jeep Liberty SUV 2012': 45, 'Ford Expedition EL SUV 2009': 45, 'Spyker C8 Convertible 2009': 45, 'Audi S4 Sedan 2007': 45, 'AM General Hummer SUV 2000': 45, 'Acura Integra Type R 2001': 45, 'Chevrolet Monte Carlo Coupe 2007': 45, 'Ford Mustang Convertible 2007': 45, 'Lamborghini Diablo Coupe 2001': 45, 'Ford Focus Sedan 2007': 45, 'Chrysler PT Cruiser Convertible 2008': 45, 'BMW M3 Coupe 2012': 45, 'Daewoo Nubira Wagon 2002': 45, 'Dodge Journey SUV 2012': 44, 'Chevrolet Traverse SUV 2012': 44, 'Dodge Caravan Minivan 1997': 44, 'Plymouth Neon Coupe 1999': 44, 'Nissan Juke Hatchback 2012': 44, 'Fisker Karma Sedan 2012': 44, 'Rolls-Royce Phantom Sedan 2012': 44, 'Porsche Panamera Sedan 2012': 44, 'Toyota Camry Sedan 2012': 44, 'Dodge Durango SUV 2012': 44, 'Toyota Corolla Sedan 2012': 44, 'Jeep Patriot SUV 2012': 44, 'Chevrolet Silverado 1500 Extended Cab 2012': 44, 'Hyundai Genesis Sedan 2012': 44, 'Chrysler Aspen SUV 2009': 44, 'Ford Freestar Minivan 2007': 44, 'HUMMER H2 SUT Crew Cab 2009': 44, 'McLaren MP4-12C Coupe 2012': 44, 'Audi V8 Sedan 1994': 44, 'Chevrolet Sonic Sedan 2012': 44, 'Hyundai Tucson SUV 2012': 44, 'BMW 6 Series Convertible 2007': 44, 'Bugatti Veyron 16.4 Coupe 2009': 44, 'Lamborghini Aventador Coupe 2012': 44, 'Dodge Ram Pickup 3500 Quad Cab 2009': 44, 'Chevrolet Silverado 1500 Regular Cab 2012': 44, 'Mercedes-Benz E-Class Sedan 2012': 44, 'Audi TTS Coupe 2012': 43, 'Acura TL Sedan 2012': 43, 'Volkswagen Beetle Hatchback 2012': 43, 'GMC Yukon Hybrid SUV 2012': 43, 'Dodge Ram Pickup 3500 Crew Cab 2010': 43, 'Spyker C8 Coupe 2009': 43, 'Land Rover Range Rover SUV 2012': 43, 'Hyundai Elantra Touring Hatchback 2012': 43, 'Ferrari 458 Italia Coupe 2012': 43, 'Audi R8 Coupe 2012': 43, 'Volkswagen Golf Hatchback 2012': 43, 'BMW 3 Series Sedan 2012': 43, 'Ford Edge SUV 2012': 43, 'Audi 100 Wagon 1994': 43, 'Cadillac CTS-V Sedan 2012': 43, 'Chevrolet Impala Sedan 2007': 43, 'Land Rover LR2 SUV 2012': 43, 'Jeep Compass SUV 2012': 43, 'Buick Rainier SUV 2007': 43, 'Volvo XC90 SUV 2007': 43, 'Audi S5 Coupe 2012': 43, 'Ford F-150 Regular Cab 2012': 43, 'Ford Fiesta Sedan 2012': 43, 'Chevrolet Silverado 1500 Classic Extended Cab 2007': 43, 'Jeep Wrangler SUV 2012': 43, 'Chrysler Crossfire Convertible 2008': 43, 'Ford F-450 Super Duty Crew Cab 2012': 42, 'Hyundai Elantra Sedan 2007': 42, 'Volvo C30 Hatchback 2012': 42, 'Chevrolet Cobalt SS 2010': 42, 'Hyundai Veracruz SUV 2012': 42, 'Dodge Charger SRT-8 2009': 42, 'Ferrari FF Coupe 2012': 42, 'Ford Ranger SuperCab 2011': 42, 'Honda Odyssey Minivan 2012': 42, 'Hyundai Santa Fe SUV 2012': 42, 'Scion xD Hatchback 2012': 42, 'Hyundai Azera Sedan 2012': 42, 'BMW 3 Series Wagon 2012': 42, 'Buick Enclave SUV 2012': 42, 'Suzuki SX4 Hatchback 2012': 42, 'Dodge Caliber Wagon 2007': 42, 'Nissan Leaf Hatchback 2012': 42, 'Audi S5 Convertible 2012': 42, 'BMW X5 SUV 2007': 42, 'Acura TL Type-S 2008': 42, 'GMC Terrain SUV 2012': 42, 'BMW X6 SUV 2012': 42, 'Dodge Charger Sedan 2012': 41, 'BMW M6 Convertible 2010': 41, 'Suzuki SX4 Sedan 2012': 41, 'BMW Z4 Convertible 2012': 41, 'Audi A5 Coupe 2012': 41, 'Dodge Dakota Crew Cab 2010': 41, 'Audi 100 Sedan 1994': 41, 'Acura TSX Sedan 2012': 41, 'Dodge Caliber Wagon 2012': 41, 'BMW 1 Series Coupe 2012': 41, 'Ram C/V Cargo Van Minivan 2012': 41, 'Audi TT Hatchback 2011': 41, 'Toyota 4Runner SUV 2012': 41, 'Chrysler Sebring Convertible 2010': 41, 'Hyundai Veloster Hatchback 2012': 41, 'Honda Odyssey Minivan 2007': 41, 'Mercedes-Benz Sprinter Van 2012': 41, 'Aston Martin V8 Vantage Coupe 2012': 41, 'Cadillac SRX SUV 2012': 41, 'BMW M5 Sedan 2010': 41, 'Audi TT RS Coupe 2012': 40, 'GMC Canyon Extended Cab 2012': 40, 'Hyundai Sonata Sedan 2012': 40, 'Dodge Sprinter Cargo Van 2009': 40, 'Isuzu Ascender SUV 2008': 40, 'Chevrolet Silverado 1500 Hybrid Crew Cab 2012': 40, 'Chevrolet TrailBlazer SS 2009': 40, 'Audi S4 Sedan 2012': 40, 'smart fortwo Convertible 2012': 40, 'Ferrari 458 Italia Convertible 2012': 40, 'Chevrolet Corvette Convertible 2012': 40, 'Dodge Magnum Wagon 2008': 40, 'Dodge Dakota Club Cab 2007': 39, 'Toyota Sequoia SUV 2012': 39, 'HUMMER H3T Crew Cab 2010': 39, 'BMW X3 SUV 2012': 39, 'Bentley Arnage Sedan 2009': 39, 'Rolls-Royce Ghost Sedan 2012': 39, 'Dodge Challenger SRT8 2011': 39, 'Honda Accord Coupe 2012': 39, 'Acura ZDX Hatchback 2012': 39, 'Ferrari California Convertible 2012': 39, 'Tesla Model S Sedan 2012': 39, 'Lincoln Town Car Sedan 2011': 39, 'Nissan NV Passenger Van 2012': 39, 'Chevrolet Malibu Hybrid Sedan 2010': 39, 'Honda Accord Sedan 2012': 39, 'Buick Verano Sedan 2012': 38, 'Chevrolet Corvette Ron Fellows Edition Z06 2007': 38, 'Ford E-Series Wagon Van 2012': 38, 'Aston Martin Virage Coupe 2012': 38, 'Chevrolet Silverado 2500HD Regular Cab 2012': 38, 'Suzuki Aerio Sedan 2007': 38, 'Chrysler Town and Country Minivan 2012': 38, 'Chevrolet HHR SS 2010': 37, 'Mercedes-Benz SL-Class Coupe 2009': 37, 'Audi RS 4 Convertible 2008': 37, 'Chevrolet Tahoe Hybrid SUV 2012': 37, 'Bentley Continental Supersports Conv. Convertible 2012': 37, 'MINI Cooper Roadster Convertible 2012': 37, 'Bentley Mulsanne Sedan 2011': 36, 'Lamborghini Gallardo LP 570-4 Superleggera 2012': 36, 'Mazda Tribute SUV 2011': 36, 'Lamborghini Reventon Coupe 2008': 36, 'BMW 1 Series Convertible 2012': 36, 'Bentley Continental GT Coupe 2012': 35, 'Chevrolet Express Van 2007': 35, 'Buick Regal GS 2012': 35, 'Hyundai Sonata Hybrid Sedan 2012': 34, 'Infiniti G Coupe IPL 2012': 34, 'BMW ActiveHybrid 5 Sedan 2012': 34, 'FIAT 500 Convertible 2012': 34, 'Infiniti QX56 SUV 2011': 33, 'Bugatti Veyron 16.4 Convertible 2009': 33, 'Aston Martin Virage Convertible 2012': 33, 'Acura RL Sedan 2012': 32, 'Rolls-Royce Phantom Drophead Coupe Convertible 2012': 31, 'Chevrolet Express Cargo Van 2007': 30, 'Maybach Landaulet Convertible 2012': 29, 'FIAT 500 Abarth 2012': 28, 'Hyundai Accent Sedan 2012': 24})\n",
            "X_train shape: (8144, 2048), X_test shape: (8041, 2048)\n",
            "Epoch 1/150, Loss: 5.4008\n",
            "Epoch 2/150, Loss: 5.0519\n",
            "Epoch 3/150, Loss: 4.8603\n",
            "Epoch 4/150, Loss: 4.7181\n",
            "Epoch 5/150, Loss: 4.5955\n",
            "Epoch 6/150, Loss: 4.4911\n",
            "Epoch 7/150, Loss: 4.3917\n",
            "Epoch 8/150, Loss: 4.2917\n",
            "Epoch 9/150, Loss: 4.2086\n",
            "Epoch 10/150, Loss: 4.1272\n",
            "Epoch 11/150, Loss: 4.0508\n",
            "Epoch 12/150, Loss: 3.9655\n",
            "Epoch 13/150, Loss: 3.8889\n",
            "Epoch 14/150, Loss: 3.8243\n",
            "Epoch 15/150, Loss: 3.7532\n",
            "Epoch 16/150, Loss: 3.6751\n",
            "Epoch 17/150, Loss: 3.6036\n",
            "Epoch 18/150, Loss: 3.5412\n",
            "Epoch 19/150, Loss: 3.4727\n",
            "Epoch 20/150, Loss: 3.4103\n",
            "Epoch 21/150, Loss: 3.3386\n",
            "Epoch 22/150, Loss: 3.2749\n",
            "Epoch 23/150, Loss: 3.2145\n",
            "Epoch 24/150, Loss: 3.1561\n",
            "Epoch 25/150, Loss: 3.0954\n",
            "Epoch 26/150, Loss: 3.0247\n",
            "Epoch 27/150, Loss: 2.9679\n",
            "Epoch 28/150, Loss: 2.9040\n",
            "Epoch 29/150, Loss: 2.8445\n",
            "Epoch 30/150, Loss: 2.7874\n",
            "Epoch 31/150, Loss: 2.7273\n",
            "Epoch 32/150, Loss: 2.6666\n",
            "Epoch 33/150, Loss: 2.6167\n",
            "Epoch 34/150, Loss: 2.5559\n",
            "Epoch 35/150, Loss: 2.4951\n",
            "Epoch 36/150, Loss: 2.4441\n",
            "Epoch 37/150, Loss: 2.3841\n",
            "Epoch 38/150, Loss: 2.3316\n",
            "Epoch 39/150, Loss: 2.2745\n",
            "Epoch 40/150, Loss: 2.2154\n",
            "Epoch 41/150, Loss: 2.1546\n",
            "Epoch 42/150, Loss: 2.1106\n",
            "Epoch 43/150, Loss: 2.0532\n",
            "Epoch 44/150, Loss: 2.0103\n",
            "Epoch 45/150, Loss: 1.9559\n",
            "Epoch 46/150, Loss: 1.9045\n",
            "Epoch 47/150, Loss: 1.8499\n",
            "Epoch 48/150, Loss: 1.7993\n",
            "Epoch 49/150, Loss: 1.7507\n",
            "Epoch 50/150, Loss: 1.7015\n",
            "Epoch 51/150, Loss: 1.6485\n",
            "Epoch 52/150, Loss: 1.5996\n",
            "Epoch 53/150, Loss: 1.5536\n",
            "Epoch 54/150, Loss: 1.4975\n",
            "Epoch 55/150, Loss: 1.4682\n",
            "Epoch 56/150, Loss: 1.4064\n",
            "Epoch 57/150, Loss: 1.3708\n",
            "Epoch 58/150, Loss: 1.3148\n",
            "Epoch 59/150, Loss: 1.2815\n",
            "Epoch 60/150, Loss: 1.2410\n",
            "Epoch 61/150, Loss: 1.1922\n",
            "Epoch 62/150, Loss: 1.1590\n",
            "Epoch 63/150, Loss: 1.1211\n",
            "Epoch 64/150, Loss: 1.0759\n",
            "Epoch 65/150, Loss: 1.0437\n",
            "Epoch 66/150, Loss: 1.0039\n",
            "Epoch 67/150, Loss: 0.9670\n",
            "Epoch 68/150, Loss: 0.9240\n",
            "Epoch 69/150, Loss: 0.8984\n",
            "Epoch 70/150, Loss: 0.8689\n",
            "Epoch 71/150, Loss: 0.8365\n",
            "Epoch 72/150, Loss: 0.8053\n",
            "Epoch 73/150, Loss: 0.7742\n",
            "Epoch 74/150, Loss: 0.7475\n",
            "Epoch 75/150, Loss: 0.7186\n",
            "Epoch 76/150, Loss: 0.6821\n",
            "Epoch 77/150, Loss: 0.6606\n",
            "Epoch 78/150, Loss: 0.6409\n",
            "Epoch 79/150, Loss: 0.6106\n",
            "Epoch 80/150, Loss: 0.5871\n",
            "Epoch 81/150, Loss: 0.5682\n",
            "Epoch 82/150, Loss: 0.5490\n",
            "Epoch 83/150, Loss: 0.5226\n",
            "Epoch 84/150, Loss: 0.5047\n",
            "Epoch 85/150, Loss: 0.4836\n",
            "Epoch 86/150, Loss: 0.4632\n",
            "Epoch 87/150, Loss: 0.4492\n",
            "Epoch 88/150, Loss: 0.4404\n",
            "Epoch 89/150, Loss: 0.4212\n",
            "Epoch 90/150, Loss: 0.4084\n",
            "Epoch 91/150, Loss: 0.3825\n",
            "Epoch 92/150, Loss: 0.3787\n",
            "Epoch 93/150, Loss: 0.3582\n",
            "Epoch 94/150, Loss: 0.3491\n",
            "Epoch 95/150, Loss: 0.3422\n",
            "Epoch 96/150, Loss: 0.3293\n",
            "Epoch 97/150, Loss: 0.3147\n",
            "Epoch 98/150, Loss: 0.3005\n",
            "Epoch 99/150, Loss: 0.2953\n",
            "Epoch 100/150, Loss: 0.2842\n",
            "Epoch 101/150, Loss: 0.2731\n",
            "Epoch 102/150, Loss: 0.2661\n",
            "Epoch 103/150, Loss: 0.2540\n",
            "Epoch 104/150, Loss: 0.2510\n",
            "Epoch 105/150, Loss: 0.2464\n",
            "Epoch 106/150, Loss: 0.2330\n",
            "Epoch 107/150, Loss: 0.2229\n",
            "Epoch 108/150, Loss: 0.2204\n",
            "Epoch 109/150, Loss: 0.2080\n",
            "Epoch 110/150, Loss: 0.2037\n",
            "Epoch 111/150, Loss: 0.1996\n",
            "Epoch 112/150, Loss: 0.1976\n",
            "Epoch 113/150, Loss: 0.1911\n",
            "Epoch 114/150, Loss: 0.1860\n",
            "Epoch 115/150, Loss: 0.1788\n",
            "Epoch 116/150, Loss: 0.1754\n",
            "Epoch 117/150, Loss: 0.1693\n",
            "Epoch 118/150, Loss: 0.1611\n",
            "Epoch 119/150, Loss: 0.1655\n",
            "Epoch 120/150, Loss: 0.1570\n",
            "Epoch 121/150, Loss: 0.1547\n",
            "Epoch 122/150, Loss: 0.1509\n",
            "Epoch 123/150, Loss: 0.1477\n",
            "Epoch 124/150, Loss: 0.1499\n",
            "Epoch 125/150, Loss: 0.1387\n",
            "Epoch 126/150, Loss: 0.1368\n",
            "Epoch 127/150, Loss: 0.1346\n",
            "Epoch 128/150, Loss: 0.1301\n",
            "Epoch 129/150, Loss: 0.1284\n",
            "Epoch 130/150, Loss: 0.1238\n",
            "Epoch 131/150, Loss: 0.1207\n",
            "Epoch 132/150, Loss: 0.1209\n",
            "Epoch 133/150, Loss: 0.1158\n",
            "Epoch 134/150, Loss: 0.1145\n",
            "Epoch 135/150, Loss: 0.1119\n",
            "Epoch 136/150, Loss: 0.1102\n",
            "Epoch 137/150, Loss: 0.1074\n",
            "Epoch 138/150, Loss: 0.1066\n",
            "Epoch 139/150, Loss: 0.1025\n",
            "Epoch 140/150, Loss: 0.1025\n",
            "Epoch 141/150, Loss: 0.0996\n",
            "Epoch 142/150, Loss: 0.0963\n",
            "Epoch 143/150, Loss: 0.0969\n",
            "Epoch 144/150, Loss: 0.0936\n",
            "Epoch 145/150, Loss: 0.0903\n",
            "Epoch 146/150, Loss: 0.0899\n",
            "Epoch 147/150, Loss: 0.0922\n",
            "Epoch 148/150, Loss: 0.0869\n",
            "Epoch 149/150, Loss: 0.0885\n",
            "Epoch 150/150, Loss: 0.0823\n",
            "I2-HOFI Model Accuracy: 0.5220\n",
            "I2-HOFI Model Precision: 0.5415\n",
            "I2-HOFI Model Recall Score: 0.5220\n",
            "I2-HOFI Model F1 Score: 0.5188\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}